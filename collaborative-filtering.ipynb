{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and loading prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from data_preparation import *\n",
    "books, ratings, users, Y, R = prepared_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model parameters and prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the initial number of dimensions of X, W and B parameters vectors to 10 in order to find a good balance between complexity and overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In X matrix, the i-th row corresponds to the feature vector for the book i. Similarly, in W matrix, the j-th row corresponds to the parameter vector for user j. The B vector corresponds to the user bias. Initially, let's set these values to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_books, num_users = Y.shape\n",
    "W = tf.Variable(np.random.normal(size=(num_users, 10)).astype(np.float32))\n",
    "B = tf.Variable(np.random.normal(size=(num_users)).astype(np.float32))\n",
    "X = tf.Variable(np.random.normal(size=(num_books, 10)).astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted rating is calculated with this pattern: $x^{(i)}$ â‹… $w^{(j)}$ + $b^{(j)}$. We count the dot product of movie feature vector and user parameter vector W and we add the user bias B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(users, books):\n",
    "    prediction = tf.reduce_sum(tf.gather(W, users) * tf.gather(X, books), axis=1)\n",
    "    prediction += tf.gather(B, users)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collaborative filtering cost function is given by adding sum of squarred errors and regularization terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collfilt_cost_func(Y):\n",
    "    non_zero_ratings = np.nonzero(Y)\n",
    "    users = non_zero_ratings[1]\n",
    "    books = non_zero_ratings[0]\n",
    "    ratings = Y[non_zero_ratings]\n",
    "\n",
    "    pred = predict(users, books)\n",
    "    cost = tf.reduce_mean(tf.square(pred - ratings))\n",
    "\n",
    "    cost += tf.reduce_sum(W**2) + tf.reduce_sum(B**2) + tf.reduce_sum(X**2)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean normalization makes the algorithm behave a lot better and faster. We normalize the ratings by computing the mean rating for each book and subtracting it from the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = np.nanmean(Y, axis=1, keepdims=True)\n",
    "Y_normalized = Y - mean_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use gradient descent to minimize the cost function. I will set the learning rate to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat fitting the parameters until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6  # threshold for the change in the cost function\n",
    "\n",
    "prev_cost = float('inf')\n",
    "while True:\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = collfilt_cost_func(Y_normalized)\n",
    "    gradients = tape.gradient(cost, [W, B, X])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, B, X]))\n",
    "    current_cost = collfilt_cost_func(Y_normalized).numpy()\n",
    "    if abs(prev_cost - current_cost) < epsilon:\n",
    "        break\n",
    "    prev_cost = current_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function that takes a list of books and their ratings and returns a list of recommended books based on the trained model. It takes a dictionary with book titles as keys and ratings as values and converts it to numpy array. Then it replace not given ratings with mean rating for each book and reshapes the array to fit the parameters. The last steps are computing the predicted ratings, selecting the highest ones and returning a list of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(user_ratings):\n",
    "    # Get an array of ratings from a dictionary\n",
    "    user_ratings_array = create_ratings_array(user_ratings, Y)\n",
    "\n",
    "    # Replace NaN values with the mean rating\n",
    "    nan_indices = np.isnan(user_ratings)\n",
    "    user_ratings[nan_indices] = np.nanmean(user_ratings)\n",
    "\n",
    "    # Reshape user_ratings and compute the predicted ratings\n",
    "    user_ratings = user_ratings.reshape(-1, 1)\n",
    "    ratings_mean = np.nanmean(ratings, axis=1).reshape(-1, 1)\n",
    "    pred = tf.matmul(X, W, transpose_b=True) + B + ratings_mean\n",
    "\n",
    "    # Get the indices of the books sorted by their predicted ratings\n",
    "    sorted_indices = np.argsort(-pred, axis=1)\n",
    "\n",
    "    # Get the ISBN numbers of the books\n",
    "    isbn_numbers = Y[:, 0]\n",
    "\n",
    "    # Get the recommended books\n",
    "    recommended_books = isbn_numbers[sorted_indices]\n",
    "\n",
    "    return recommended_books"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
