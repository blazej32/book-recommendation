{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and loading prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from data_preparation import *\n",
    "books, ratings, users, Y, R = prepared_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model parameters and prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the initial number of dimensions of X, W and B parameters vectors to 10 in order to find a good balance between complexity and overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In X matrix, the i-th row corresponds to the feature vector for the book i. Similarly, in W matrix, the j-th row corresponds to the parameter vector for user j. The B vector corresponds to the user bias. Initially, let's set these values to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_books, num_users = Y.shape\n",
    "W = tf.Variable(np.random.normal(size=(num_users, 10)).astype(np.float32))\n",
    "B = tf.Variable(np.random.normal(size=(num_users)).astype(np.float32))\n",
    "X = tf.Variable(np.random.normal(size=(num_books, 10)).astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted rating is calculated with this pattern: $x^{(i)}$ â‹… $w^{(j)}$ + $b^{(j)}$. We count the dot product of movie feature vector and user parameter vector W and we add the user bias B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(users, books):\n",
    "    prediction = tf.reduce_sum(tf.gather(W, users) * tf.gather(X, books), axis=1)\n",
    "    prediction += tf.gather(B, users)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collaborative filtering cost function is given by adding sum of squarred errors and regularization terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collfilt_cost_func(Y):\n",
    "    non_zero_ratings = np.nonzero(Y)\n",
    "    users = non_zero_ratings[1]\n",
    "    books = non_zero_ratings[0]\n",
    "    ratings = Y[non_zero_ratings]\n",
    "\n",
    "    pred = predict(users, books)\n",
    "    cost = tf.reduce_mean(tf.square(pred - ratings))\n",
    "\n",
    "    cost += tf.reduce_sum(W**2) + tf.reduce_sum(B**2) + tf.reduce_sum(X**2)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean normalization makes the algorithm behave a lot better and faster. We normalize the ratings by computing the mean rating for each book and subtracting it from the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = np.nanmean(Y, axis=1, keepdims=True)\n",
    "Y_normalized = Y - mean_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use gradient descent to minimize the cost function. I will set the learning rate to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
